{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages, set options for displaying and for generating reproducable results (random seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Numpy: 1.14.0\n",
      "Pandas: 0.22.0\n",
      "XGBoost: 0.7.post3\n",
      "sklearn: 0.19.1\n",
      "matplotlib: 1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import xgboost\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, cross_val_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,log_loss, accuracy_score, make_scorer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(\"Numpy:\",np.__version__)\n",
    "print(\"Pandas:\",pd.__version__)\n",
    "print(\"XGBoost:\",xgboost.__version__)\n",
    "print(\"sklearn:\",sklearn.__version__)\n",
    "print(\"matplotlib:\",matplotlib.__version__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) #sklearn throws too much deprecationwarnings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('precision', 3)\n",
    "np.set_printoptions(precision=3)\n",
    "FONT_SIZE=16\n",
    "params = {'legend.fontsize': FONT_SIZE,\n",
    "         'axes.labelsize': FONT_SIZE,\n",
    "         'axes.titlesize':FONT_SIZE,\n",
    "         'figure.figsize': (8, 4),\n",
    "         'xtick.labelsize':FONT_SIZE,\n",
    "         'ytick.labelsize':FONT_SIZE}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "#rc={'axes.labelsize': FONT_SIZE, 'font.size': FONT_SIZE, 'legend.fontsize': FONT_SIZE, 'axes.titlesize': FONT_SIZE,'xtick.labelsize': FONT_SIZE, 'ytick.labelsize': FONT_SIZE}\n",
    "#plt.rcParams.update(**rc)\n",
    "\n",
    "\n",
    "\n",
    "seed = 1234\n",
    "#seed = None\n",
    "\n",
    "DPI=1200\n",
    "\n",
    "#XGBoost config\n",
    "params = {\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.26046515748913901,\n",
    "    'silent': 0,\n",
    "    'n_estimators': 110,\n",
    "    'colsample_bytree': 0.81958831684028921,\n",
    "    'gamma':0.25,\n",
    "    'subsample':0.93168572417786366,\n",
    "    'min_child_weight':0.9,\n",
    "    'colsample_bylevel':1,\n",
    "    'max_delta_step':0,\n",
    "    'reg_alpha':0,\n",
    "    'scale_pos_weight':1,\n",
    "    'missing':None,\n",
    "    'objective': 'multi:softmax',\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "#RandomForest config\n",
    "RF_N_TREES=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: (8528,)\n",
      "['A' 'N' 'O' '~']\n",
      "DF after dropna: (8528, 386)\n",
      "X after imputer:(8528, 386)\n"
     ]
    }
   ],
   "source": [
    "input_file = \"/notebooks/data/ait_result_dataset.V37.csv\"\n",
    "df = pd.read_csv(input_file, header = 0)\n",
    "df=df.drop('target',axis=1)\n",
    "ref=pd.read_csv('/notebooks/References/REF_V3.csv',header=None)\n",
    "rec=ref[0]\n",
    "y=ref[1].as_matrix()\n",
    "print(\"y: \"+str(y.shape))\n",
    "classes= np.unique(y)\n",
    "print(classes)\n",
    "df=df.dropna(axis=1, how='all')\n",
    "print(\"DF after dropna: \"+str(df.shape))\n",
    "X=df.as_matrix()\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0,verbose=1)\n",
    "X=imp.fit_transform(X)\n",
    "print(\"X after imputer:\"+str(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define common used test metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define common functions for evaluating the classifier, like F1-CinC Score (Mean of Normal, Average, Other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "#global f1_classes_cv\n",
    "\n",
    "def test_classifier(clf,X,y):\n",
    "    \n",
    "    def my_custom_f1(y_true, predictions):\n",
    "        f1_classes=f1_score(y_true, predictions, labels=classes, average=None)\n",
    "        f1_classes_cv.append(f1_classes)\n",
    "        f1_custom=f1_score(y_true, predictions, labels=['N','A','O'], average='macro')\n",
    "        #print(\"F1 scores: \",f1_classes)\n",
    "        #print(\"F1 mean: {0:.3f}\".format(f1_custom))\n",
    "        return f1_custom\n",
    "\n",
    "\n",
    "\n",
    "    predictions = clf.predict(X)\n",
    "    #print(\"F1: {:1.4f}\".format(f1_score(y, predictions,labels=['N','A','O'],average='macro')))  \n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if (y[i] == predictions[i]):\n",
    "            correct += 1\n",
    "    acc = accuracy_score(y, predictions)\n",
    "    #print('Predicted correctly: {0}/{1}'.format(correct, len(predictions)))\n",
    "    #print('Error: {0:.4f}'.format(1-acc))\n",
    "    #scorer = make_scorer(f1_score, labels=['A','O','N'], average='macro')\n",
    "    #global f1_classes_cv\n",
    "    f1_classes_cv=[]\n",
    "    scorer = make_scorer(my_custom_f1)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv,scoring=scorer)\n",
    "    #print(f1_classes_cv)\n",
    "    f1_classes_cv=np.vstack(f1_classes_cv)\n",
    "    f1_classes_cv=np.mean(f1_classes_cv,axis=0)\n",
    "\n",
    "    print(\"== 5-fold CV ==\")\n",
    "    print(\"F1 scores 5-fold CV per iteration:\",scores)\n",
    "    print(\"F1 mean 5-fold CV per class:\",f1_classes_cv)\n",
    "    print(\"F1 mean 5-fold CV: {0:.3f}\".format(np.mean(scores)))\n",
    "    return np.mean(scores),f1_classes_cv\n",
    "\n",
    "# Generator that returns time differences\n",
    "def TicTocGenerator():\n",
    "    ti = 0 \n",
    "    tf = time.time()\n",
    "    while True:\n",
    "        ti = tf\n",
    "        tf = time.time()\n",
    "        yield tf-ti\n",
    "\n",
    "TicToc = TicTocGenerator()\n",
    "\n",
    "def toc(tempBool=True):\n",
    "    tempTimeInterval = next(TicToc)\n",
    "    if tempBool:\n",
    "        print( \"Elapsed time: %f seconds.\\n\" %tempTimeInterval)\n",
    "        return tempTimeInterval\n",
    "\n",
    "def tic(id):\n",
    "    print( \"Tic: %s\" %id)\n",
    "    toc(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test features by importance and random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: [50, 100, 200, 300, 386], Number of runs: 10\n",
      "\n",
      "Testing 50 features\n",
      "\n",
      "50, Iteration 1 Seed 868296\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.825 0.822 0.812 0.826 0.836]\n",
      "F1 mean 5-fold CV per class: [0.822 0.902 0.748 0.634]\n",
      "F1 mean 5-fold CV: 0.824\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.833 0.831 0.831 0.822 0.824]\n",
      "F1 mean 5-fold CV per class: [0.823 0.905 0.756 0.617]\n",
      "F1 mean 5-fold CV: 0.828\n",
      "\n",
      "50, Iteration 2 Seed 880779\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.824 0.832 0.824 0.83  0.831]\n",
      "F1 mean 5-fold CV per class: [0.829 0.903 0.752 0.646]\n",
      "F1 mean 5-fold CV: 0.828\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.835 0.838 0.819 0.822 0.827]\n",
      "F1 mean 5-fold CV per class: [0.827 0.904 0.754 0.608]\n",
      "F1 mean 5-fold CV: 0.828\n",
      "\n",
      "50, Iteration 3 Seed 424822\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.832 0.843 0.805 0.823 0.835]\n",
      "F1 mean 5-fold CV per class: [0.825 0.904 0.754 0.644]\n",
      "F1 mean 5-fold CV: 0.828\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.832 0.843 0.813 0.823 0.821]\n",
      "F1 mean 5-fold CV per class: [0.825 0.903 0.752 0.612]\n",
      "F1 mean 5-fold CV: 0.826\n",
      "\n",
      "50, Iteration 4 Seed 13682\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.827 0.827 0.819 0.832 0.838]\n",
      "F1 mean 5-fold CV per class: [0.829 0.904 0.753 0.648]\n",
      "F1 mean 5-fold CV: 0.829\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.834 0.84  0.813 0.82  0.828]\n",
      "F1 mean 5-fold CV per class: [0.824 0.903 0.754 0.59 ]\n",
      "F1 mean 5-fold CV: 0.827\n",
      "\n",
      "50, Iteration 5 Seed 259541\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.816 0.827 0.841 0.833 0.83 ]\n",
      "F1 mean 5-fold CV per class: [0.828 0.904 0.756 0.628]\n",
      "F1 mean 5-fold CV: 0.829\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.81  0.825 0.84  0.825 0.835]\n",
      "F1 mean 5-fold CV per class: [0.824 0.903 0.753 0.615]\n",
      "F1 mean 5-fold CV: 0.827\n",
      "\n",
      "50, Iteration 6 Seed 529061\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.843 0.81  0.82  0.825 0.832]\n",
      "F1 mean 5-fold CV per class: [0.821 0.903 0.754 0.619]\n",
      "F1 mean 5-fold CV: 0.826\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.837 0.805 0.818 0.829 0.833]\n",
      "F1 mean 5-fold CV per class: [0.82  0.903 0.75  0.61 ]\n",
      "F1 mean 5-fold CV: 0.824\n",
      "\n",
      "50, Iteration 7 Seed 792133\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.839 0.838 0.822 0.834 0.813]\n",
      "F1 mean 5-fold CV per class: [0.832 0.902 0.754 0.635]\n",
      "F1 mean 5-fold CV: 0.829\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.837 0.826 0.824 0.836 0.813]\n",
      "F1 mean 5-fold CV per class: [0.825 0.903 0.753 0.617]\n",
      "F1 mean 5-fold CV: 0.827\n",
      "\n",
      "50, Iteration 8 Seed 582789\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.824 0.809 0.822 0.832 0.836]\n",
      "F1 mean 5-fold CV per class: [0.82  0.903 0.751 0.635]\n",
      "F1 mean 5-fold CV: 0.825\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.82  0.816 0.834 0.835 0.826]\n",
      "F1 mean 5-fold CV per class: [0.823 0.902 0.753 0.614]\n",
      "F1 mean 5-fold CV: 0.826\n",
      "\n",
      "50, Iteration 9 Seed 904006\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.826 0.811 0.814 0.832 0.843]\n",
      "F1 mean 5-fold CV per class: [0.822 0.902 0.751 0.626]\n",
      "F1 mean 5-fold CV: 0.825\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.835 0.817 0.821 0.835 0.839]\n",
      "F1 mean 5-fold CV per class: [0.825 0.905 0.757 0.607]\n",
      "F1 mean 5-fold CV: 0.829\n",
      "\n",
      "50, Iteration 10 Seed 379485\n",
      "(8528, 50)\n",
      "== 5-fold CV ==\n",
      "F1 scores 5-fold CV per iteration: [0.825 0.822 0.829 0.82  0.821]\n",
      "F1 mean 5-fold CV per class: [0.816 0.903 0.751 0.647]\n",
      "F1 mean 5-fold CV: 0.823\n",
      "(8528, 50)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-16c00fa5a556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mX_reduced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRF_N_TREES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_reduced\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdf_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Seed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'RF'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1 Normal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1 AF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1 Other'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1 Noise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feat_dha=pd.read_excel('/notebooks/data/fi_merged.xlsx')\n",
    "\n",
    "fi_sorted_xgb=feat_dha.sort_values(by='ImportanceXGB', ascending=False)\n",
    "fi_sorted_rf=feat_dha.sort_values(by='ImportanceRF', ascending=False)\n",
    "\n",
    "#idx_range=np.arange(1,387,1)\n",
    "number_of_runs=10\n",
    "idx_range=[50,100,200,300,386]\n",
    "\n",
    "print(\"Range: \"+str(idx_range)+ \", Number of runs: \"+str(number_of_runs))\n",
    "\n",
    "df_results=pd.DataFrame(columns=['Count','Iteration','Seed','Classifier','F1','F1 Normal','F1 AF','F1 Other','F1 Noise'])\n",
    "\n",
    "for idx in idx_range:\n",
    "    print(\"\\nTesting \"+str(idx)+ \" features\")\n",
    "    for i in range(1,number_of_runs+1):\n",
    "        seed = datetime.datetime.now().microsecond\n",
    "        print('\\n'+str(idx)+', Iteration',i,'Seed',seed)\n",
    "\n",
    "        cv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=seed)\n",
    "\n",
    "        #XGBoost\n",
    "        #display(idx)\n",
    "        feature_names=fi_sorted_xgb.tail(n=386-idx).Name\n",
    "        df_reduced=df.drop(feature_names,axis=1)\n",
    "        X_reduced=df_reduced.as_matrix()\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0,verbose=1)\n",
    "        X_reduced=imp.fit_transform(X_reduced)\n",
    "        print(X_reduced.shape)\n",
    "        clf = XGBClassifier(**params).fit(X_reduced, y,verbose=50)\n",
    "        a1, a2=test_classifier(clf,X_reduced,y)\n",
    "        df_results=df_results.append({'Count': idx,'Iteration':i,'Seed':seed,'Classifier':'XGB','F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3]},ignore_index=True)\n",
    "\n",
    "        #Random Forest\n",
    "        feature_names=fi_sorted_rf.tail(n=386-idx).Name\n",
    "        df_reduced=df.drop(feature_names,axis=1)\n",
    "        X_reduced=df_reduced.as_matrix()\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0,verbose=1)\n",
    "        X_reduced=imp.fit_transform(X_reduced)\n",
    "        print(X_reduced.shape)\n",
    "        clf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X_reduced, y)\n",
    "        a1, a2=test_classifier(clf,X_reduced,y)\n",
    "        df_results=df_results.append({'Count': idx,'Iteration':i,'Seed':seed,'Classifier':'RF','F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3]},ignore_index=True)\n",
    "\n",
    "        joblib.dump(df_results, 'top_n_feat.pkl', compress = 1)\n",
    "#joblib.dump(f1_class_scores, 'f1_class_scores_rf.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 Normal</th>\n",
       "      <th>F1 AF</th>\n",
       "      <th>F1 Other</th>\n",
       "      <th>F1 Noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>687480</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>687480</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>975667</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>975667</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>82464</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>82464</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>254158</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>254158</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>224739</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>224739</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>152894</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>152894</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>208411</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>208411</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>262566</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>262566</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>239256</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>239256</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>482740</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>482740</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>82470</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>82470</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>823262</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>823262</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>705511</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>705511</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>942245</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>942245</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>386</td>\n",
       "      <td>3</td>\n",
       "      <td>641926</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>386</td>\n",
       "      <td>3</td>\n",
       "      <td>641926</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count Iteration    Seed Classifier     F1  F1 Normal  F1 AF  F1 Other  \\\n",
       "0     50         1  687480        XGB  0.804      0.894  0.804     0.714   \n",
       "1     50         1  687480         RF  0.803      0.893  0.793     0.723   \n",
       "2     50         2  975667        XGB  0.809      0.896  0.810     0.719   \n",
       "3     50         2  975667         RF  0.809      0.893  0.807     0.727   \n",
       "4     50         3   82464        XGB  0.803      0.895  0.800     0.715   \n",
       "5     50         3   82464         RF  0.806      0.893  0.803     0.721   \n",
       "6    100         1  254158        XGB  0.809      0.895  0.813     0.720   \n",
       "7    100         1  254158         RF  0.808      0.896  0.798     0.731   \n",
       "8    100         2  224739        XGB  0.807      0.895  0.809     0.716   \n",
       "9    100         2  224739         RF  0.815      0.895  0.817     0.733   \n",
       "10   100         3  152894        XGB  0.806      0.893  0.809     0.716   \n",
       "11   100         3  152894         RF  0.810      0.898  0.801     0.731   \n",
       "12   200         1  208411        XGB  0.812      0.897  0.815     0.723   \n",
       "13   200         1  208411         RF  0.809      0.894  0.805     0.728   \n",
       "14   200         2  262566        XGB  0.812      0.897  0.819     0.721   \n",
       "15   200         2  262566         RF  0.811      0.897  0.801     0.734   \n",
       "16   200         3  239256        XGB  0.811      0.896  0.817     0.721   \n",
       "17   200         3  239256         RF  0.816      0.896  0.819     0.734   \n",
       "18   300         1  482740        XGB  0.811      0.896  0.816     0.721   \n",
       "19   300         1  482740         RF  0.814      0.895  0.816     0.730   \n",
       "20   300         2   82470        XGB  0.810      0.897  0.810     0.724   \n",
       "21   300         2   82470         RF  0.812      0.893  0.817     0.726   \n",
       "22   300         3  823262        XGB  0.815      0.898  0.820     0.726   \n",
       "23   300         3  823262         RF  0.804      0.892  0.798     0.723   \n",
       "24   386         1  705511        XGB  0.813      0.898  0.818     0.722   \n",
       "25   386         1  705511         RF  0.804      0.894  0.799     0.718   \n",
       "26   386         2  942245        XGB  0.812      0.895  0.818     0.723   \n",
       "27   386         2  942245         RF  0.807      0.896  0.800     0.725   \n",
       "28   386         3  641926        XGB  0.814      0.898  0.819     0.725   \n",
       "29   386         3  641926         RF  0.808      0.896  0.802     0.728   \n",
       "\n",
       "    F1 Noise  \n",
       "0      0.599  \n",
       "1      0.578  \n",
       "2      0.592  \n",
       "3      0.563  \n",
       "4      0.592  \n",
       "5      0.561  \n",
       "6      0.637  \n",
       "7      0.549  \n",
       "8      0.649  \n",
       "9      0.575  \n",
       "10     0.622  \n",
       "11     0.566  \n",
       "12     0.621  \n",
       "13     0.594  \n",
       "14     0.627  \n",
       "15     0.575  \n",
       "16     0.631  \n",
       "17     0.605  \n",
       "18     0.641  \n",
       "19     0.577  \n",
       "20     0.624  \n",
       "21     0.610  \n",
       "22     0.633  \n",
       "23     0.597  \n",
       "24     0.649  \n",
       "25     0.550  \n",
       "26     0.631  \n",
       "27     0.582  \n",
       "28     0.635  \n",
       "29     0.593  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test by reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REFERENCES = ['REF_V1','REF_V2','REF_V3','REF_TEIJERO','REF_KROPF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame(columns=['Reference','Classifier','F1','F1 Normal','F1 AF','F1 Other','F1 Noise'])\n",
    "\n",
    "for reference in REFERENCES:\n",
    "    ref=pd.read_csv('/notebooks/References/'+reference+'.csv',header=None)\n",
    "    y=ref[1].as_matrix()\n",
    "    bst = XGBClassifier(**params).fit(X, y,verbose=50)\n",
    "    [a1,a2]=test_classifier(bst,X,y)\n",
    "    df_results=df_results.append({'Reference':reference,'Classifier':'XGB', 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3]},ignore_index=True)\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X, y)\n",
    "    [a1,a2]=test_classifier(rf,X,y)\n",
    "    df_results=df_results.append({'Reference':reference,'Classifier':'RF', 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3]},ignore_index=True)\n",
    "    display(df_results)\n",
    "\n",
    "joblib.dump(df_results, 'f1_by_reference.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barchart: F1 score by reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "df_results=joblib.load('f1_by_reference.pkl')\n",
    "#current_palette_4 = sns.color_palette(\"hls\", 4)\n",
    "#sns.set_palette(current_palette_4)\n",
    "\n",
    "n_groups = len(REFERENCES)\n",
    "index = np.arange(n_groups)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "\n",
    "#sns.set_context(\"paper\")\n",
    "#plt.style.use(['seaborn-paper', 'seaborn-white'])\n",
    "#matplotlib.rc(\"font\", family=\"Times New Roman\")\n",
    "\n",
    "\n",
    "params = {'legend.fontsize': FONT_SIZE,\n",
    "         'axes.labelsize': FONT_SIZE,\n",
    "         'axes.titlesize':FONT_SIZE,\n",
    "         'figure.figsize': (9, 4),\n",
    "         'xtick.labelsize':FONT_SIZE,\n",
    "         'ytick.labelsize':FONT_SIZE}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rects1 = ax.bar(index, df_results[df_results.Classifier=='XGB'].F1, bar_width,\n",
    "                alpha=opacity, color='black',\n",
    "                yerr=None, error_kw=error_config,\n",
    "                label='XGBoost')\n",
    "\n",
    "rects2 = ax.bar(index + bar_width, df_results[df_results.Classifier=='RF'].F1, bar_width,\n",
    "                alpha=opacity, color='white', edgecolor=['black']*len(index),\n",
    "                yerr=None, error_kw=error_config,linewidth=2.0,\n",
    "                label='Random Forest')\n",
    "\n",
    "#x.set_xlabel('Reference',fontsize=FONT_SIZE)\n",
    "ax.set_ylabel('F1$_{CinC}$',fontsize=FONT_SIZE)\n",
    "#ax.set_title('F1 score by reference and classifier')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(REFERENCES)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_ylim([0.825,0.86])\n",
    "ax.grid()\n",
    "#fig.set_facecolor('white')\n",
    "#plt.rcParams['axes.facecolor']='white'\n",
    "#plt.rcParams['savefig.facecolor']='white'\n",
    "#plt.rcParams['savefig.force_edgecolor'] = True\n",
    "#plt.rcParams['savefig.edgecolor'] = 'black'\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('/notebooks/data/barchart_f1_score_by_reference.png',dpi=DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=joblib.load('top_n_feat.pkl.100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results[df_results.Classifier=='XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results[df_results.Classifier=='RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test by feature category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_dha=pd.read_excel('/notebooks/data/fi_merged.xlsx')\n",
    "categories=feat_dha.Category.unique()\n",
    "categories=np.sort(categories)\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame(columns=['Category','Classifier','Importance','F1','F1 Normal','F1 AF','F1 Other','F1 Noise','Count'])\n",
    "\n",
    "for category in categories:\n",
    "    feat_sum_xgb= feat_dha[feat_dha.Category==category].ImportanceXGB.sum()    \n",
    "    feat_sum_rf= feat_dha[feat_dha.Category==category].ImportanceRF.sum()\n",
    "    \n",
    "    feat_count_xgb= len(feat_dha[feat_dha.Category==category].ImportanceXGB)\n",
    "    feat_count_rf= len(feat_dha[feat_dha.Category==category].ImportanceRF)\n",
    "\n",
    "    print(category,feat_sum_xgb,feat_sum_rf)\n",
    "    df_new = df[feat_dha[feat_dha.Category==category].Name]\n",
    "    X=df_new.as_matrix()\n",
    "    print(\"X: \"+str(X.shape))\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0,verbose=1)\n",
    "    X_new=imp.fit_transform(X)    \n",
    "\n",
    "    bst = XGBClassifier(**params).fit(X_new, y,verbose=50)\n",
    "    [a1,a2]=test_classifier(bst,X_new,y)\n",
    "    df_results=df_results.append({'Category':category,'Classifier':'XGB','Importance':feat_sum_xgb, 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Count':feat_count_xgb},ignore_index=True)\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X_new, y)\n",
    "    [a1,a2]=test_classifier(rf,X_new,y)\n",
    "    df_results=df_results.append({'Category':category,'Classifier':'RF','Importance':feat_sum_rf, 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Count':feat_count_rf},ignore_index=True)\n",
    "    \n",
    "joblib.dump(df_results, 'f1_by_category.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Test by excluding category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame(columns=['Category','Classifier','Importance','F1','F1 Normal','F1 AF','F1 Other','F1 Noise','Count'])\n",
    "\n",
    "#categories=np.append(categories,'All')\n",
    "#categories=np.sort(categories)\n",
    "\n",
    "for category in categories:\n",
    "    feat_sum_xgb= feat_dha[feat_dha.Category!=category].ImportanceXGB.sum()    \n",
    "    feat_sum_rf= feat_dha[feat_dha.Category!=category].ImportanceRF.sum()\n",
    "    \n",
    "    feat_count_xgb= len(feat_dha[feat_dha.Category!=category].ImportanceXGB)\n",
    "    feat_count_rf= len(feat_dha[feat_dha.Category!=category].ImportanceRF)\n",
    "\n",
    "    print(category,feat_sum_xgb,feat_sum_rf)\n",
    "    df_new = df[feat_dha[feat_dha.Category!=category].Name]\n",
    "    X=df_new.as_matrix()\n",
    "    print(\"X: \"+str(X.shape))\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0,verbose=1)\n",
    "    X_new=imp.fit_transform(X)    \n",
    "\n",
    "    bst = XGBClassifier(**params).fit(X_new, y,verbose=50)\n",
    "    [a1,a2]=test_classifier(bst,X_new,y)\n",
    "    df_results=df_results.append({'Category':category,'Classifier':'XGB','Importance':feat_sum_xgb, 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Count':feat_count_xgb},ignore_index=True)\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X_new, y)\n",
    "    [a1,a2]=test_classifier(rf,X_new,y)\n",
    "    df_results=df_results.append({'Category':category,'Classifier':'RF','Importance':feat_sum_rf, 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Count':feat_count_rf},ignore_index=True)\n",
    "    \n",
    "joblib.dump(df_results, 'f1_by_excluding_category.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test by excluding category and meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=pd.DataFrame(columns=['Category','Classifier','Importance','F1','F1 Normal','F1 AF','F1 Other','F1 Noise','Count'])\n",
    "\n",
    "#categories=np.append(categories,'All')\n",
    "#categories=np.sort(categories)\n",
    "\n",
    "for category in categories:\n",
    "    feat_sum_xgb= feat_dha[(feat_dha.Category!=category) & (feat_dha.Category!='Meta')].ImportanceXGB.sum()    \n",
    "    feat_sum_rf= feat_dha[(feat_dha.Category!=category) & (feat_dha.Category!='Meta')].ImportanceRF.sum()\n",
    "    \n",
    "    feat_count_xgb= len(feat_dha[(feat_dha.Category!=category) & (feat_dha.Category!='Meta')].ImportanceXGB)\n",
    "    feat_count_rf= len(feat_dha[(feat_dha.Category!=category) & (feat_dha.Category!='Meta')].ImportanceRF)\n",
    "\n",
    "    print(category,feat_sum_xgb,feat_sum_rf)\n",
    "    df_new = df[feat_dha[(feat_dha.Category!=category) & (feat_dha.Category!='Meta')].Name]\n",
    "    X=df_new.as_matrix()\n",
    "    print(\"X: \"+str(X.shape))\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0,verbose=1)\n",
    "    X_new=imp.fit_transform(X)    \n",
    "\n",
    "    bst = XGBClassifier(**params).fit(X_new, y,verbose=50)\n",
    "    [a1,a2]=test_classifier(bst,X_new,y)\n",
    "    df_results=df_results.append({'Category':category,'Classifier':'XGB','Importance':feat_sum_xgb, 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Count':feat_count_xgb},ignore_index=True)\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X_new, y)\n",
    "    [a1,a2]=test_classifier(rf,X_new,y)\n",
    "    df_results=df_results.append({'Category':category,'Classifier':'RF','Importance':feat_sum_rf, 'F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Count':feat_count_rf},ignore_index=True)\n",
    "    \n",
    "joblib.dump(df_results, 'f1_by_excluding_category_and_meta.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results=joblib.load('f1_by_category.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results[df_results.Classifier=='XGB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results[df_results.Classifier=='RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barchart: Feature importance by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_groups = len(categories)\n",
    "index = np.arange(n_groups)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "\n",
    "\n",
    "rects1 = ax.bar(index, df_results[df_results.Classifier=='XGB'].Importance, bar_width,\n",
    "                alpha=opacity, color='black',\n",
    "                yerr=None, error_kw=error_config,\n",
    "                label='XGBoost')\n",
    "\n",
    "\n",
    "#ax.set_xlabel('Category',fontsize=FONT_SIZE)\n",
    "ax.set_ylabel('Importance',fontsize=FONT_SIZE)\n",
    "ax.set_xticks(index+bar_width/2)\n",
    "ax.set_xticklabels(categories)\n",
    "#ax.legend(loc=\"upper left\")\n",
    "ax.grid()\n",
    "#plt.style.use('paper')\n",
    "ax.set_ylim([0,0.35])\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "params = {'legend.fontsize': FONT_SIZE,\n",
    "         'axes.labelsize': FONT_SIZE,\n",
    "         'axes.titlesize':FONT_SIZE,\n",
    "         'figure.figsize': (7, 4),\n",
    "         'xtick.labelsize':FONT_SIZE,\n",
    "         'ytick.labelsize':FONT_SIZE}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('/notebooks/data/barchart_feature_importance_by_category.png',dpi=DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barchart: F1 score by category and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_groups = len(categories)\n",
    "index = np.arange(n_groups)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 1\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = ax.bar(index, df_results[df_results.Classifier=='XGB'].F1, bar_width,\n",
    "                alpha=opacity, color='black',\n",
    "                yerr=None, error_kw=error_config,\n",
    "                label='XGBoost')\n",
    "\n",
    "#rects2 = ax.bar(index + bar_width, df_results[df_results.Classifier=='RF'].F1, bar_width,\n",
    "#                alpha=opacity, color='b',\n",
    "#                yerr=None, error_kw=error_config,\n",
    "#                label='Random Forest')\n",
    "\n",
    "#ax.set_xlabel('Category')\n",
    "ax.set_ylabel('F1$_{CinC}$')\n",
    "#ax.set_title('F1 on subset of features per category')\n",
    "ax.set_xticks(index + bar_width/2)\n",
    "ax.set_xticklabels(categories)\n",
    "#ax.legend(loc=\"upper left\")\n",
    "ax.set_ylim([0.3,0.85])\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('/notebooks/data/barchart_f1_by_category.png',dpi=DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barchart: F1 score by excluded category and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=joblib.load('f1_by_excluding_category.pkl')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_width = 0.35\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "rc={'axes.labelsize': FONT_SIZE, 'font.size': FONT_SIZE, 'legend.fontsize': FONT_SIZE, 'axes.titlesize': FONT_SIZE,'xtick.labelsize': FONT_SIZE, 'ytick.labelsize': FONT_SIZE}\n",
    "plt.rcParams.update(**rc)\n",
    "\n",
    "n_groups = len(categories)\n",
    "\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "\n",
    "rects1 = ax.bar(index, df_results[df_results.Classifier=='XGB'].F1, bar_width,\n",
    "                alpha=opacity,color='b',\n",
    "                yerr=None, error_kw=error_config,\n",
    "                label='XGBoost')\n",
    "\n",
    "rects2 = ax.bar(index + bar_width, df_results[df_results.Classifier=='RF'].F1, bar_width,\n",
    "                alpha=opacity,\n",
    "                yerr=None, error_kw=error_config,color='r',\n",
    "                label='Random Forest')\n",
    "\n",
    "#ax.set_xlabel('Category')\n",
    "ax.set_ylabel('F1')\n",
    "#ax.set_title('F1 on subset of features per category')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend(loc=\"upper left\")\n",
    "#ax.set_ylim([0.815,0.85])\n",
    "ax.set_ylim([0.81,0.85])\n",
    "ax.grid()\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.plot();\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig('/notebooks/data/barchart_f1_by_excluded_category_and_classifier.png',dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Number of features - F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=joblib.load('top_n_feat.pkl')\n",
    "\n",
    "\n",
    "plt.figure(0)\n",
    "ax = plt.axes()\n",
    "\n",
    "\n",
    "ax.set_xticks([100, 200,300])\n",
    "\n",
    "plt.grid()\n",
    "params = {'legend.fontsize': FONT_SIZE,\n",
    "         'axes.labelsize': FONT_SIZE,\n",
    "         'axes.titlesize':FONT_SIZE,\n",
    "         'figure.figsize': (5, 4),\n",
    "         'xtick.labelsize':FONT_SIZE,\n",
    "         'ytick.labelsize':FONT_SIZE}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "plt.plot(df_results[df_results.Classifier=='XGB'].F1.reset_index(drop=True), color='cornflowerblue',label='XGBoost')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('5-fold CV F1$_{CinC}$ score')\n",
    "plt.plot(df_results[df_results.Classifier=='RF'].F1.reset_index(drop=True), color='red',label='Random Forest')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1$_{CinC}$ score')\n",
    "plt.xlabel('Number of features')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('linechart_n_feat_vs_f1.png',dpi=DPI)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "ax = plt.axes()\n",
    "ax.set_xticks([100, 200,300])\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('5-fold CV F1$_{CinC}$ score')\n",
    "plt.plot(df_results[df_results.Classifier=='XGB']['F1 Normal'].reset_index(drop=True), label='Normal')\n",
    "plt.plot(df_results[df_results.Classifier=='XGB']['F1 AF'].reset_index(drop=True), label='AF')\n",
    "plt.plot(df_results[df_results.Classifier=='XGB']['F1 Other'].reset_index(drop=True), label='Other')\n",
    "plt.plot(df_results[df_results.Classifier=='XGB']['F1 Noise'].reset_index(drop=True), label='Noise')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Number of features')\n",
    "plt.rcParams.update(params)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('linechart_n_feat_vs_f1_per_class.png',dpi=DPI)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for statistical difference on N runs with random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the classifier N times using a pseudo-random seed, based on current microsecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N=100 #number of runs\n",
    "\n",
    "df_results=pd.DataFrame(columns=['Iteration','Seed','Classifier','F1','F1 Normal','F1 AF','F1 Other','F1 Noise','Training Time'])\n",
    "\n",
    "for i in range(1,N+1):\n",
    "    print('\\nIteration',i,'Seed',seed)\n",
    "    seed = datetime.datetime.now().microsecond\n",
    "    cv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    tic('Train XGB')\n",
    "    bst = XGBClassifier(**params).fit(X, y,verbose=50)\n",
    "    train_xgb_time=toc()\n",
    "    a1,a2=test_classifier(bst,X,y)\n",
    "    df_results=df_results.append({'Iteration': i,'Seed':seed,'Classifier':'XGB','F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Training Time':train_xgb_time},ignore_index=True)\n",
    "\n",
    "    tic('Train RF')\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X, y)\n",
    "    train_rf_time=toc()\n",
    "    a1,a2=test_classifier(rf,X,y)\n",
    "    df_results=df_results.append({'Iteration': i,'Seed':seed,'Classifier':'RF','F1':a1,'F1 Normal':a2[1],'F1 AF':a2[0],'F1 Other':a2[2],'F1 Noise':a2[3],'Training Time':train_rf_time},ignore_index=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "joblib.dump(df_results, 'f1_100_runs.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot: XGB vs. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=joblib.load('f1_100_runs.pkl')\n",
    "mpl.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "print(\"XGB: %.3f +/- %.3f, RF %.3f +/- %.3f\"%(df_results[df_results.Classifier=='XGB'].F1.mean(),df_results[df_results.Classifier=='XGB'].F1.std(),df_results[df_results.Classifier=='RF'].F1.mean(),df_results[df_results.Classifier=='RF'].F1.std()))\n",
    "statistic,p_value=stats.ttest_rel(df_results[df_results.Classifier=='XGB'].F1,df_results[df_results.Classifier=='RF'].F1)\n",
    "print('p-Value: %.50f' % (float(p_value)))\n",
    "statistic,p_value=stats.wilcoxon(df_results[df_results.Classifier=='XGB'].F1,df_results[df_results.Classifier=='RF'].F1)\n",
    "print('p-Value: %.50f' % (float(p_value)))\n",
    "                                                        \n",
    "df_f1_xgb=df_results[df_results.Classifier=='XGB'].F1.reset_index(drop=True)\n",
    "df_f1_rf=df_results[df_results.Classifier=='RF'].F1.reset_index(drop=True)\n",
    "df_f1=pd.concat([df_f1_xgb,df_f1_rf],axis=1)\n",
    "\n",
    "df_f1.columns = ['XGBoost', 'Random Forest']\n",
    "#display(df_f1)\n",
    "\n",
    "#sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "plt.style.use(['seaborn-paper', 'seaborn-white'])\n",
    "#matplotlib.rc(\"font\", family=\"Times New Roman\")\n",
    "\n",
    "rc={'axes.labelsize': FONT_SIZE, 'font.size': FONT_SIZE, 'legend.fontsize': FONT_SIZE, 'axes.titlesize': FONT_SIZE,'xtick.labelsize': FONT_SIZE, 'ytick.labelsize': FONT_SIZE}\n",
    "plt.rcParams.update(**rc)\n",
    "\n",
    "ax = sns.boxplot(data=df_f1)\n",
    "  \n",
    "box = ax.artists[1]\n",
    "box.set_facecolor('white')\n",
    "\n",
    "box = ax.artists[0]\n",
    "box.set_facecolor('black')\n",
    "box.set_edgecolor('white')\n",
    "\n",
    "\n",
    "\n",
    "x1, x2 = 0, 1 \n",
    "y, h, col = df_f1_xgb.max()+0.001, 0.0010, 'k'\n",
    "ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.2, c=col)\n",
    "ax.text((x1+x2)*.5, y+h, \"p < 0.00001\", ha='center', va='bottom')\n",
    "ax.grid()\n",
    "fig = ax.get_figure()\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig('boxplot_xgb_vs_rf.png', format='png', dpi=DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fi_table(clf,df):\n",
    "    fi=pd.DataFrame(clf.feature_importances_)\n",
    "    #display(fi)\n",
    "    fi.columns = ['Importance']\n",
    "    cols=pd.DataFrame(list(df.columns))\n",
    "    cols.columns = ['Feature']\n",
    "    result = pd.concat( [fi, cols], axis=1)\n",
    "    fi_sorted=result.sort_values(by='Importance', ascending=False)\n",
    "    return fi_sorted\n",
    "\n",
    "fi_sorted=fi_table(rf,df)\n",
    "fi_sorted.to_excel('/notebooks/data/fi_rf.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic('Train XGB')\n",
    "print(params)\n",
    "bst = XGBClassifier(**params).fit(X, y,verbose=50)\n",
    "joblib.dump(bst, 'xgboost_joblib.pkl', compress = 1)\n",
    "a=toc()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic('Test XGB')\n",
    "test_classifier(bst,X,y)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic('Test XGB prediction runtime')\n",
    "y=bst.predict(X)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic('Train RF')\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed,n_estimators=RF_N_TREES).fit(X, y)\n",
    "joblib.dump(rf,'rf_joblib.pkl', compress = 1)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic('Test RF')\n",
    "test_classifier(rf, X,y)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tic('Test RF prediction runtime')\n",
    "y=rf.predict(X)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validated predictions of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(bst, X, y,cv=cv)\n",
    "answers = pd.concat([rec,pd.DataFrame(y_pred)], axis=1)\n",
    "answers.to_csv('y_5xCV_xgb.txt',index=None,header=None)\n",
    "\n",
    "y_pred = cross_val_predict(rf, X, y,cv=cv)\n",
    "answers = pd.concat([rec,pd.DataFrame(y_pred)], axis=1)\n",
    "answers.to_csv('y_5xCV_rf.txt',index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network: Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(alpha=0.01, random_state=seed)\n",
    "\n",
    "nn=nn.fit(X, y)    \n",
    "print(nn)\n",
    "test_classifier(nn,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_results=joblib.load('f1_by_category.pkl')\n",
    "df_results=df_results.replace('Average beat','Average')\n",
    "df_results=df_results.replace('QRS detection','QRS')\n",
    "joblib.dump(df_results, 'f1_by_category.pkl', compress = 1)\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
